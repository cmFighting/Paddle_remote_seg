{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨常规赛：遥感影像地块分割 - 9月第3名方案\n",
    "\n",
    "本次的飞桨常规赛主要是对遥感影像进行像素级内容解析，并对遥感影像中感兴趣的类别进行提取和分类，以衡量遥感影像地块分割模型在多个类别（如建筑、道路、林地等）上的效果。\n",
    "\n",
    "我采用的方案是deeplabv3+, 并使用了diceloss替换了原先的celoss, 在GPU的环境下训练了8个小时左右得到的50.316的精度, 整体的训练和测试流程如下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据处理和paddleseg框架安装\r\n",
    "\r\n",
    "模型训练之前我们需要将将数据进行解压, 并生成相应的训练集和验证集的txt文件。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "/home/aistudio/tmp_data\n"
     ]
    }
   ],
   "source": [
    "# 解压数据\r\n",
    "%cd /home/aistudio/data/data80164/\r\n",
    "!unzip -oq /home/aistudio/data/data80164/train_and_label.zip\r\n",
    "!unzip -oq /home/aistudio/data/data80164/img_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work\n",
      "Cloning into 'PaddleSeg'...\n",
      "remote: Enumerating objects: 2532, done.\u001b[K\n",
      "remote: Counting objects: 100% (2532/2532), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1400/1400), done.\u001b[K\n",
      "remote: Total 14316 (delta 1403), reused 2166 (delta 1102), pack-reused 11784\u001b[K\n",
      "Receiving objects: 100% (14316/14316), 337.68 MiB | 24.50 MiB/s, done.\n",
      "Resolving deltas: 100% (9235/9235), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "# 安装paddleseg框架\r\n",
    "%cd /home/aistudio/work\r\n",
    "!git clone https://gitee.com/paddlepaddle/PaddleSeg.git\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/PaddleSeg\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddleseg\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/f9/c42edf1e595478d9578595aa23dbae848b68553b98048f6457c3c4c9003d/paddleseg-2.3.0-py3-none-any.whl (236kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 10.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flake8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (3.8.2)\n",
      "Requirement already satisfied: visualdl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (2.2.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (4.1.1.26)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (4.36.1)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (0.7.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (1.6.3)\n",
      "Requirement already satisfied: yapf==0.26.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (0.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (3.0.12)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (1.21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleseg) (5.1.2)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddleseg) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddleseg) (2.2.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddleseg) (0.23)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddleseg) (2.6.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.1.1)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (0.8.53)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (0.7.1.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.15.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (2.22.0)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (2.2.3)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (7.1.2)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (3.14.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddleseg) (1.1.5)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddleseg) (1.4.10)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddleseg) (1.3.0)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddleseg) (16.7.9)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddleseg) (2.0.1)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddleseg) (0.10.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddleseg) (1.3.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8->paddleseg) (0.6.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (2.10.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (0.16.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddleseg) (7.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddleseg) (0.18.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddleseg) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddleseg) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddleseg) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddleseg) (3.0.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg) (2019.3)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddleseg) (2.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddleseg) (1.1.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8->paddleseg) (7.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->paddleseg) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl>=2.0.0->paddleseg) (56.2.0)\n",
      "Installing collected packages: paddleseg\n",
      "Successfully installed paddleseg-2.3.0\n",
      "Connecting to https://paddleseg.bj.bcebos.com/dataset/optic_disc_seg.zip\n",
      "Downloading optic_disc_seg.zip\n",
      "[==================================================] 100.00%\n",
      "Uncompress optic_disc_seg.zip\n",
      "[==================================================] 100.00%\n",
      "2021-10-16 10:37:14 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 1000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.01\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  pretrained: null\n",
      "  type: BiSeNetV2\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: data/optic_disc_seg\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: OpticDiscSeg\n",
      "val_dataset:\n",
      "  dataset_root: data/optic_disc_seg\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 512\n",
      "    - 512\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: OpticDiscSeg\n",
      "------------------------------------------------\n",
      "W1016 10:37:14.319491  1003 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1016 10:37:14.319532  1003 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "2021-10-16 10:37:23 [INFO]\tNumber of predict images = 1\n",
      "2021-10-16 10:37:23 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/optic_disc/bisenet_optic_disc_512x512_1k/model.pdparams\n",
      "Connecting to https://bj.bcebos.com/paddleseg/dygraph/optic_disc/bisenet_optic_disc_512x512_1k/model.pdparams\n",
      "Downloading model.pdparams\n",
      "[==================================================] 100.00%\n",
      "2021-10-16 10:37:25 [INFO]\tThere are 356/356 variables loaded into BiSeNetV2.\n",
      "2021-10-16 10:37:25 [INFO]\tStart to predict...\n",
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    }
   ],
   "source": [
    "# 安装并测试paddleseg\r\n",
    "%cd PaddleSeg\r\n",
    "!pip install paddleseg\r\n",
    "!python predict.py --config configs/quick_start/bisenet_optic_disc_512x512_1k.yml --model_path https://bj.bcebos.com/paddleseg/dygraph/optic_disc/bisenet_optic_disc_512x512_1k/model.pdparams --image_path docs/images/optic_test_image.jpg --save_dir output/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 分割数据集, 将数据集安装7: 3的比例分成训练集和验证集, 帮助后面我们在训练过程中保存表现最好的模型\r\n",
    "%cd /home/aistudio/data/data80164/\r\n",
    "!python tools/split_dataset_list.py /home/aistudio/tmp_data/ img_train lab_train --label_class '0' '1' '2' '3'  --format jpg png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练\n",
    "\n",
    "现在我们已经准备好了数据集和训练语义分割模型所要使用的框架和paddleseg\n",
    "\n",
    "我们使用deeplabv3p作为我们的基本方法，主干特征提取网络选择为resnet50vd，损失函数则使用diceloss，相对于celoss而言对分割的表达能力更强，可以计算全局的分割相似度。借助paddleseg框架，\n",
    "我们只需要在PaddleSeg的`configs/deeplabv3p/`目录下建立一个`deeplabv3p_remote.yml`的配置文件即可, 配置文件的内容如下：\n",
    "\n",
    "```yaml\n",
    "batch_size: 4\n",
    "iters: 80000\n",
    "\n",
    "\n",
    "train_dataset: #训练数据设置\n",
    "  type: Dataset #选择数据集格式\n",
    "  dataset_root: /home/aistudio/data/data80164/ # 选择数据集路径\n",
    "  train_path: /home/aistudio/data/data80164/train.txt\n",
    "  num_classes: 4 #指定目标的类别个数（背景也算为一类）\n",
    "  transforms: #数据预处理/增强的方式\n",
    "    - type: Resize #送入网络之前需要进行resize\n",
    "      target_size: [256, 256] #将原图resize成512*512再送入网络\n",
    "    - type: RandomHorizontalFlip #采用水平反转的方式进行数据增强\n",
    "    - type: Normalize #图像进行归一化\n",
    "  mode: train\n",
    "\n",
    "val_dataset: #验证数据设置\n",
    "  type: Dataset #选择数据集格式\n",
    "  dataset_root: /home/aistudio/data/data80164/ #选择数据集路径\n",
    "  val_path: /home/aistudio/data/data80164/val.txt\n",
    "  num_classes: 4 #指定目标的类别个数（背景也算为一类）\n",
    "  transforms: #数据预处理/增强的方式\n",
    "    - type: Resize  #将原图resize成512*512在送入网络\n",
    "      target_size: [256, 256]  #将原图resize成512*512在送入网络\n",
    "    - type: Normalize #图像进行归一化\n",
    "  mode: val\n",
    "\n",
    "\n",
    "optimizer:\n",
    "  type: sgd\n",
    "  momentum: 0.9\n",
    "  weight_decay: 4.0e-5\n",
    "\n",
    "lr_scheduler:\n",
    "  type: PolynomialDecay\n",
    "  learning_rate: 0.01\n",
    "  end_lr: 0\n",
    "  power: 0.9\n",
    "\n",
    "loss:\n",
    "  types:\n",
    "    - type: DiceLoss\n",
    "  coef: [1]\n",
    "\n",
    "model:\n",
    "  type: DeepLabV3P\n",
    "  backbone:\n",
    "    type: ResNet50_vd\n",
    "    output_stride: 8\n",
    "    multi_grid: [1, 2, 4]\n",
    "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
    "  backbone_indices: [0, 3]\n",
    "  aspp_ratios: [1, 12, 24, 36]\n",
    "  aspp_out_channels: 256\n",
    "  align_corners: True\n",
    "  pretrained:None\n",
    "```\n",
    "完成之后，直接执行下面的脚本完成训练过程即可，其中batchsize大家可以根据自己的机器型号来进行调整。\n",
    "训练完成之后的模型将会保存在`output/models_remote/deeplabv3p`目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/PaddleSeg\n",
      "2021-10-16 11:06:53 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.4.0-150-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
      "cudnn: 7.6\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: Tesla V100-SXM2-32GB']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddlePaddle: 2.1.2\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n",
      "2021-10-16 11:06:53 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 80000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: DiceLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.01\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  align_corners: true\n",
      "  aspp_out_channels: 256\n",
      "  aspp_ratios:\n",
      "  - 1\n",
      "  - 12\n",
      "  - 24\n",
      "  - 36\n",
      "  backbone:\n",
      "    multi_grid:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    output_stride: 8\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "    type: ResNet50_vd\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 3\n",
      "  type: DeepLabV3P\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio/data/data80164/\n",
      "  mode: train\n",
      "  num_classes: 4\n",
      "  train_path: /home/aistudio/data/data80164/train.txt\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio/data/data80164/\n",
      "  mode: val\n",
      "  num_classes: 4\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/data/data80164/val.txt\n",
      "------------------------------------------------\n",
      "W1016 11:06:54.209396  3313 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1016 11:06:54.209439  3313 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "2021-10-16 11:07:02 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "2021-10-16 11:07:04 [INFO]\tThere are 275/275 variables loaded into ResNet_vd.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:239: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.bool, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "2021-10-16 11:07:10 [INFO]\t[TRAIN] epoch: 1, iter: 10/80000, loss: 0.8076, lr: 0.009999, batch_cost: 0.5480, reader_cost: 0.04205, ips: 7.2999 samples/sec | ETA 12:10:30\n",
      "2021-10-16 11:07:15 [INFO]\t[TRAIN] epoch: 1, iter: 20/80000, loss: 0.8010, lr: 0.009998, batch_cost: 0.5024, reader_cost: 0.00011, ips: 7.9621 samples/sec | ETA 11:09:40\n",
      "2021-10-16 11:07:20 [INFO]\t[TRAIN] epoch: 1, iter: 30/80000, loss: 0.7652, lr: 0.009997, batch_cost: 0.5040, reader_cost: 0.00012, ips: 7.9360 samples/sec | ETA 11:11:47\n",
      "2021-10-16 11:07:25 [INFO]\t[TRAIN] epoch: 1, iter: 40/80000, loss: 0.7590, lr: 0.009996, batch_cost: 0.5021, reader_cost: 0.00011, ips: 7.9669 samples/sec | ETA 11:09:06\n",
      "2021-10-16 11:07:30 [INFO]\t[TRAIN] epoch: 1, iter: 50/80000, loss: 0.6632, lr: 0.009994, batch_cost: 0.5026, reader_cost: 0.00011, ips: 7.9589 samples/sec | ETA 11:09:41\n",
      "2021-10-16 11:07:35 [INFO]\t[TRAIN] epoch: 1, iter: 60/80000, loss: 0.7336, lr: 0.009993, batch_cost: 0.5042, reader_cost: 0.00011, ips: 7.9330 samples/sec | ETA 11:11:47\n",
      "2021-10-16 11:07:40 [INFO]\t[TRAIN] epoch: 1, iter: 70/80000, loss: 0.7770, lr: 0.009992, batch_cost: 0.5029, reader_cost: 0.00011, ips: 7.9534 samples/sec | ETA 11:09:59\n",
      "2021-10-16 11:07:45 [INFO]\t[TRAIN] epoch: 1, iter: 80/80000, loss: 0.7701, lr: 0.009991, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9521 samples/sec | ETA 11:10:00\n",
      "2021-10-16 11:07:50 [INFO]\t[TRAIN] epoch: 1, iter: 90/80000, loss: 0.7233, lr: 0.009990, batch_cost: 0.5028, reader_cost: 0.00013, ips: 7.9555 samples/sec | ETA 11:09:38\n",
      "2021-10-16 11:07:55 [INFO]\t[TRAIN] epoch: 1, iter: 100/80000, loss: 0.6813, lr: 0.009989, batch_cost: 0.5033, reader_cost: 0.00010, ips: 7.9474 samples/sec | ETA 11:10:14\n",
      "2021-10-16 11:08:00 [INFO]\t[TRAIN] epoch: 1, iter: 110/80000, loss: 0.6831, lr: 0.009988, batch_cost: 0.5029, reader_cost: 0.00010, ips: 7.9542 samples/sec | ETA 11:09:35\n",
      "2021-10-16 11:08:05 [INFO]\t[TRAIN] epoch: 1, iter: 120/80000, loss: 0.7417, lr: 0.009987, batch_cost: 0.5029, reader_cost: 0.00010, ips: 7.9537 samples/sec | ETA 11:09:32\n",
      "2021-10-16 11:08:10 [INFO]\t[TRAIN] epoch: 1, iter: 130/80000, loss: 0.7726, lr: 0.009985, batch_cost: 0.5032, reader_cost: 0.00011, ips: 7.9487 samples/sec | ETA 11:09:52\n",
      "2021-10-16 11:08:15 [INFO]\t[TRAIN] epoch: 1, iter: 140/80000, loss: 0.6976, lr: 0.009984, batch_cost: 0.5029, reader_cost: 0.00012, ips: 7.9545 samples/sec | ETA 11:09:18\n",
      "2021-10-16 11:08:21 [INFO]\t[TRAIN] epoch: 1, iter: 150/80000, loss: 0.6717, lr: 0.009983, batch_cost: 0.5037, reader_cost: 0.00087, ips: 7.9409 samples/sec | ETA 11:10:22\n",
      "2021-10-16 11:08:26 [INFO]\t[TRAIN] epoch: 1, iter: 160/80000, loss: 0.6352, lr: 0.009982, batch_cost: 0.5029, reader_cost: 0.00011, ips: 7.9537 samples/sec | ETA 11:09:12\n",
      "2021-10-16 11:08:31 [INFO]\t[TRAIN] epoch: 1, iter: 170/80000, loss: 0.6781, lr: 0.009981, batch_cost: 0.5033, reader_cost: 0.00011, ips: 7.9473 samples/sec | ETA 11:09:39\n",
      "2021-10-16 11:08:36 [INFO]\t[TRAIN] epoch: 1, iter: 180/80000, loss: 0.7194, lr: 0.009980, batch_cost: 0.5032, reader_cost: 0.00010, ips: 7.9491 samples/sec | ETA 11:09:25\n",
      "2021-10-16 11:08:41 [INFO]\t[TRAIN] epoch: 1, iter: 190/80000, loss: 0.6514, lr: 0.009979, batch_cost: 0.5022, reader_cost: 0.00010, ips: 7.9649 samples/sec | ETA 11:08:00\n",
      "2021-10-16 11:08:46 [INFO]\t[TRAIN] epoch: 1, iter: 200/80000, loss: 0.6421, lr: 0.009978, batch_cost: 0.5023, reader_cost: 0.00011, ips: 7.9639 samples/sec | ETA 11:08:00\n",
      "2021-10-16 11:08:51 [INFO]\t[TRAIN] epoch: 1, iter: 210/80000, loss: 0.6583, lr: 0.009976, batch_cost: 0.5046, reader_cost: 0.00011, ips: 7.9273 samples/sec | ETA 11:11:01\n",
      "2021-10-16 11:08:56 [INFO]\t[TRAIN] epoch: 1, iter: 220/80000, loss: 0.6369, lr: 0.009975, batch_cost: 0.5025, reader_cost: 0.00011, ips: 7.9601 samples/sec | ETA 11:08:10\n",
      "2021-10-16 11:09:01 [INFO]\t[TRAIN] epoch: 1, iter: 230/80000, loss: 0.7207, lr: 0.009974, batch_cost: 0.5035, reader_cost: 0.00012, ips: 7.9447 samples/sec | ETA 11:09:22\n",
      "2021-10-16 11:09:06 [INFO]\t[TRAIN] epoch: 1, iter: 240/80000, loss: 0.7209, lr: 0.009973, batch_cost: 0.5024, reader_cost: 0.00011, ips: 7.9612 samples/sec | ETA 11:07:54\n",
      "2021-10-16 11:09:11 [INFO]\t[TRAIN] epoch: 1, iter: 250/80000, loss: 0.6787, lr: 0.009972, batch_cost: 0.5031, reader_cost: 0.00010, ips: 7.9509 samples/sec | ETA 11:08:41\n",
      "2021-10-16 11:09:16 [INFO]\t[TRAIN] epoch: 1, iter: 260/80000, loss: 0.6202, lr: 0.009971, batch_cost: 0.5032, reader_cost: 0.00010, ips: 7.9490 samples/sec | ETA 11:08:45\n",
      "2021-10-16 11:09:21 [INFO]\t[TRAIN] epoch: 1, iter: 270/80000, loss: 0.6216, lr: 0.009970, batch_cost: 0.5031, reader_cost: 0.00010, ips: 7.9509 samples/sec | ETA 11:08:31\n",
      "2021-10-16 11:09:26 [INFO]\t[TRAIN] epoch: 1, iter: 280/80000, loss: 0.6214, lr: 0.009969, batch_cost: 0.5022, reader_cost: 0.00010, ips: 7.9652 samples/sec | ETA 11:07:14\n",
      "2021-10-16 11:09:31 [INFO]\t[TRAIN] epoch: 1, iter: 290/80000, loss: 0.6352, lr: 0.009967, batch_cost: 0.5031, reader_cost: 0.00011, ips: 7.9507 samples/sec | ETA 11:08:22\n",
      "2021-10-16 11:09:36 [INFO]\t[TRAIN] epoch: 1, iter: 300/80000, loss: 0.6796, lr: 0.009966, batch_cost: 0.5030, reader_cost: 0.00012, ips: 7.9518 samples/sec | ETA 11:08:11\n",
      "2021-10-16 11:09:41 [INFO]\t[TRAIN] epoch: 1, iter: 310/80000, loss: 0.6183, lr: 0.009965, batch_cost: 0.5020, reader_cost: 0.00010, ips: 7.9676 samples/sec | ETA 11:06:47\n",
      "2021-10-16 11:09:46 [INFO]\t[TRAIN] epoch: 1, iter: 320/80000, loss: 0.5987, lr: 0.009964, batch_cost: 0.5025, reader_cost: 0.00010, ips: 7.9605 samples/sec | ETA 11:07:17\n",
      "2021-10-16 11:09:51 [INFO]\t[TRAIN] epoch: 1, iter: 330/80000, loss: 0.6032, lr: 0.009963, batch_cost: 0.5033, reader_cost: 0.00010, ips: 7.9470 samples/sec | ETA 11:08:20\n",
      "2021-10-16 11:09:56 [INFO]\t[TRAIN] epoch: 1, iter: 340/80000, loss: 0.6047, lr: 0.009962, batch_cost: 0.5032, reader_cost: 0.00009, ips: 7.9485 samples/sec | ETA 11:08:07\n",
      "2021-10-16 11:10:01 [INFO]\t[TRAIN] epoch: 1, iter: 350/80000, loss: 0.5918, lr: 0.009961, batch_cost: 0.5026, reader_cost: 0.00009, ips: 7.9593 samples/sec | ETA 11:07:08\n",
      "2021-10-16 11:10:06 [INFO]\t[TRAIN] epoch: 1, iter: 360/80000, loss: 0.6185, lr: 0.009960, batch_cost: 0.5039, reader_cost: 0.00012, ips: 7.9385 samples/sec | ETA 11:08:48\n",
      "2021-10-16 11:10:11 [INFO]\t[TRAIN] epoch: 1, iter: 370/80000, loss: 0.5885, lr: 0.009958, batch_cost: 0.5030, reader_cost: 0.00012, ips: 7.9527 samples/sec | ETA 11:07:31\n",
      "2021-10-16 11:10:16 [INFO]\t[TRAIN] epoch: 1, iter: 380/80000, loss: 0.6144, lr: 0.009957, batch_cost: 0.5040, reader_cost: 0.00011, ips: 7.9368 samples/sec | ETA 11:08:47\n",
      "2021-10-16 11:10:21 [INFO]\t[TRAIN] epoch: 1, iter: 390/80000, loss: 0.6082, lr: 0.009956, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9524 samples/sec | ETA 11:07:23\n",
      "2021-10-16 11:10:26 [INFO]\t[TRAIN] epoch: 1, iter: 400/80000, loss: 0.6507, lr: 0.009955, batch_cost: 0.5030, reader_cost: 0.00010, ips: 7.9524 samples/sec | ETA 11:07:18\n",
      "2021-10-16 11:10:31 [INFO]\t[TRAIN] epoch: 1, iter: 410/80000, loss: 0.6347, lr: 0.009954, batch_cost: 0.5034, reader_cost: 0.00010, ips: 7.9458 samples/sec | ETA 11:07:46\n",
      "2021-10-16 11:10:36 [INFO]\t[TRAIN] epoch: 1, iter: 420/80000, loss: 0.7097, lr: 0.009953, batch_cost: 0.5031, reader_cost: 0.00010, ips: 7.9501 samples/sec | ETA 11:07:19\n",
      "2021-10-16 11:10:41 [INFO]\t[TRAIN] epoch: 1, iter: 430/80000, loss: 0.6779, lr: 0.009952, batch_cost: 0.5023, reader_cost: 0.00009, ips: 7.9639 samples/sec | ETA 11:06:05\n",
      "2021-10-16 11:10:46 [INFO]\t[TRAIN] epoch: 1, iter: 440/80000, loss: 0.6402, lr: 0.009951, batch_cost: 0.5031, reader_cost: 0.00010, ips: 7.9513 samples/sec | ETA 11:07:03\n",
      "2021-10-16 11:10:51 [INFO]\t[TRAIN] epoch: 1, iter: 450/80000, loss: 0.6118, lr: 0.009949, batch_cost: 0.5028, reader_cost: 0.00010, ips: 7.9559 samples/sec | ETA 11:06:35\n",
      "2021-10-16 11:10:56 [INFO]\t[TRAIN] epoch: 1, iter: 460/80000, loss: 0.6918, lr: 0.009948, batch_cost: 0.5029, reader_cost: 0.00013, ips: 7.9543 samples/sec | ETA 11:06:38\n",
      "2021-10-16 11:11:01 [INFO]\t[TRAIN] epoch: 1, iter: 470/80000, loss: 0.6968, lr: 0.009947, batch_cost: 0.5017, reader_cost: 0.00009, ips: 7.9730 samples/sec | ETA 11:04:59\n",
      "2021-10-16 11:11:06 [INFO]\t[TRAIN] epoch: 1, iter: 480/80000, loss: 0.5989, lr: 0.009946, batch_cost: 0.5030, reader_cost: 0.00010, ips: 7.9524 samples/sec | ETA 11:06:37\n",
      "2021-10-16 11:11:12 [INFO]\t[TRAIN] epoch: 1, iter: 490/80000, loss: 0.6736, lr: 0.009945, batch_cost: 0.5020, reader_cost: 0.00010, ips: 7.9675 samples/sec | ETA 11:05:16\n",
      "2021-10-16 11:11:17 [INFO]\t[TRAIN] epoch: 1, iter: 500/80000, loss: 0.6918, lr: 0.009944, batch_cost: 0.5025, reader_cost: 0.00010, ips: 7.9601 samples/sec | ETA 11:05:49\n",
      "2021-10-16 11:11:22 [INFO]\t[TRAIN] epoch: 1, iter: 510/80000, loss: 0.7028, lr: 0.009943, batch_cost: 0.5040, reader_cost: 0.00011, ips: 7.9367 samples/sec | ETA 11:07:41\n",
      "2021-10-16 11:11:27 [INFO]\t[TRAIN] epoch: 1, iter: 520/80000, loss: 0.6171, lr: 0.009942, batch_cost: 0.5036, reader_cost: 0.00011, ips: 7.9423 samples/sec | ETA 11:07:08\n",
      "2021-10-16 11:11:32 [INFO]\t[TRAIN] epoch: 1, iter: 530/80000, loss: 0.7382, lr: 0.009940, batch_cost: 0.5034, reader_cost: 0.00011, ips: 7.9467 samples/sec | ETA 11:06:41\n",
      "2021-10-16 11:11:37 [INFO]\t[TRAIN] epoch: 1, iter: 540/80000, loss: 0.5910, lr: 0.009939, batch_cost: 0.5029, reader_cost: 0.00012, ips: 7.9547 samples/sec | ETA 11:05:56\n",
      "2021-10-16 11:11:42 [INFO]\t[TRAIN] epoch: 1, iter: 550/80000, loss: 0.5790, lr: 0.009938, batch_cost: 0.5028, reader_cost: 0.00010, ips: 7.9554 samples/sec | ETA 11:05:47\n",
      "2021-10-16 11:11:47 [INFO]\t[TRAIN] epoch: 1, iter: 560/80000, loss: 0.6604, lr: 0.009937, batch_cost: 0.5025, reader_cost: 0.00010, ips: 7.9600 samples/sec | ETA 11:05:19\n",
      "2021-10-16 11:11:52 [INFO]\t[TRAIN] epoch: 1, iter: 570/80000, loss: 0.6834, lr: 0.009936, batch_cost: 0.5025, reader_cost: 0.00009, ips: 7.9595 samples/sec | ETA 11:05:17\n",
      "2021-10-16 11:11:57 [INFO]\t[TRAIN] epoch: 1, iter: 580/80000, loss: 0.6194, lr: 0.009935, batch_cost: 0.5036, reader_cost: 0.00010, ips: 7.9427 samples/sec | ETA 11:06:36\n",
      "2021-10-16 11:12:02 [INFO]\t[TRAIN] epoch: 1, iter: 590/80000, loss: 0.5767, lr: 0.009934, batch_cost: 0.5027, reader_cost: 0.00009, ips: 7.9566 samples/sec | ETA 11:05:21\n",
      "2021-10-16 11:12:07 [INFO]\t[TRAIN] epoch: 1, iter: 600/80000, loss: 0.6145, lr: 0.009933, batch_cost: 0.5035, reader_cost: 0.00011, ips: 7.9444 samples/sec | ETA 11:06:17\n",
      "2021-10-16 11:12:12 [INFO]\t[TRAIN] epoch: 1, iter: 610/80000, loss: 0.6068, lr: 0.009931, batch_cost: 0.5022, reader_cost: 0.00011, ips: 7.9653 samples/sec | ETA 11:04:27\n",
      "2021-10-16 11:12:17 [INFO]\t[TRAIN] epoch: 1, iter: 620/80000, loss: 0.5429, lr: 0.009930, batch_cost: 0.4983, reader_cost: 0.00157, ips: 8.0280 samples/sec | ETA 10:59:11\n",
      "2021-10-16 11:12:22 [INFO]\t[TRAIN] epoch: 1, iter: 630/80000, loss: 0.5387, lr: 0.009929, batch_cost: 0.5008, reader_cost: 0.00011, ips: 7.9868 samples/sec | ETA 11:02:30\n",
      "2021-10-16 11:12:27 [INFO]\t[TRAIN] epoch: 1, iter: 640/80000, loss: 0.6087, lr: 0.009928, batch_cost: 0.5021, reader_cost: 0.00010, ips: 7.9660 samples/sec | ETA 11:04:09\n",
      "2021-10-16 11:12:32 [INFO]\t[TRAIN] epoch: 1, iter: 650/80000, loss: 0.6106, lr: 0.009927, batch_cost: 0.5027, reader_cost: 0.00009, ips: 7.9571 samples/sec | ETA 11:04:48\n",
      "2021-10-16 11:12:37 [INFO]\t[TRAIN] epoch: 1, iter: 660/80000, loss: 0.6295, lr: 0.009926, batch_cost: 0.5045, reader_cost: 0.00010, ips: 7.9279 samples/sec | ETA 11:07:10\n",
      "2021-10-16 11:12:42 [INFO]\t[TRAIN] epoch: 1, iter: 670/80000, loss: 0.4893, lr: 0.009925, batch_cost: 0.5034, reader_cost: 0.00011, ips: 7.9453 samples/sec | ETA 11:05:38\n",
      "2021-10-16 11:12:47 [INFO]\t[TRAIN] epoch: 1, iter: 680/80000, loss: 0.5590, lr: 0.009924, batch_cost: 0.5036, reader_cost: 0.00012, ips: 7.9422 samples/sec | ETA 11:05:48\n",
      "2021-10-16 11:12:52 [INFO]\t[TRAIN] epoch: 1, iter: 690/80000, loss: 0.5625, lr: 0.009922, batch_cost: 0.5037, reader_cost: 0.00012, ips: 7.9405 samples/sec | ETA 11:05:51\n",
      "2021-10-16 11:12:57 [INFO]\t[TRAIN] epoch: 1, iter: 700/80000, loss: 0.6047, lr: 0.009921, batch_cost: 0.5019, reader_cost: 0.00011, ips: 7.9698 samples/sec | ETA 11:03:20\n",
      "2021-10-16 11:13:02 [INFO]\t[TRAIN] epoch: 1, iter: 710/80000, loss: 0.7058, lr: 0.009920, batch_cost: 0.5022, reader_cost: 0.00009, ips: 7.9644 samples/sec | ETA 11:03:42\n",
      "2021-10-16 11:13:07 [INFO]\t[TRAIN] epoch: 1, iter: 720/80000, loss: 0.5727, lr: 0.009919, batch_cost: 0.5027, reader_cost: 0.00011, ips: 7.9563 samples/sec | ETA 11:04:17\n",
      "2021-10-16 11:13:12 [INFO]\t[TRAIN] epoch: 1, iter: 730/80000, loss: 0.6393, lr: 0.009918, batch_cost: 0.5030, reader_cost: 0.00010, ips: 7.9525 samples/sec | ETA 11:04:31\n",
      "2021-10-16 11:13:17 [INFO]\t[TRAIN] epoch: 1, iter: 740/80000, loss: 0.6081, lr: 0.009917, batch_cost: 0.5034, reader_cost: 0.00011, ips: 7.9467 samples/sec | ETA 11:04:55\n",
      "2021-10-16 11:13:22 [INFO]\t[TRAIN] epoch: 1, iter: 750/80000, loss: 0.7072, lr: 0.009916, batch_cost: 0.5037, reader_cost: 0.00012, ips: 7.9418 samples/sec | ETA 11:05:15\n",
      "2021-10-16 11:13:27 [INFO]\t[TRAIN] epoch: 1, iter: 760/80000, loss: 0.6619, lr: 0.009915, batch_cost: 0.5027, reader_cost: 0.00012, ips: 7.9564 samples/sec | ETA 11:03:57\n",
      "2021-10-16 11:13:32 [INFO]\t[TRAIN] epoch: 1, iter: 770/80000, loss: 0.6132, lr: 0.009913, batch_cost: 0.5029, reader_cost: 0.00012, ips: 7.9542 samples/sec | ETA 11:04:02\n",
      "2021-10-16 11:13:37 [INFO]\t[TRAIN] epoch: 1, iter: 780/80000, loss: 0.6548, lr: 0.009912, batch_cost: 0.5031, reader_cost: 0.00012, ips: 7.9500 samples/sec | ETA 11:04:19\n",
      "2021-10-16 11:13:42 [INFO]\t[TRAIN] epoch: 1, iter: 790/80000, loss: 0.6442, lr: 0.009911, batch_cost: 0.5023, reader_cost: 0.00012, ips: 7.9631 samples/sec | ETA 11:03:08\n",
      "2021-10-16 11:13:47 [INFO]\t[TRAIN] epoch: 1, iter: 800/80000, loss: 0.5774, lr: 0.009910, batch_cost: 0.5038, reader_cost: 0.00012, ips: 7.9396 samples/sec | ETA 11:05:01\n",
      "2021-10-16 11:13:52 [INFO]\t[TRAIN] epoch: 1, iter: 810/80000, loss: 0.6260, lr: 0.009909, batch_cost: 0.5035, reader_cost: 0.00011, ips: 7.9448 samples/sec | ETA 11:04:30\n",
      "2021-10-16 11:13:57 [INFO]\t[TRAIN] epoch: 1, iter: 820/80000, loss: 0.5442, lr: 0.009908, batch_cost: 0.5037, reader_cost: 0.00012, ips: 7.9409 samples/sec | ETA 11:04:44\n",
      "2021-10-16 11:14:03 [INFO]\t[TRAIN] epoch: 1, iter: 830/80000, loss: 0.6611, lr: 0.009907, batch_cost: 0.5035, reader_cost: 0.00012, ips: 7.9449 samples/sec | ETA 11:04:19\n",
      "2021-10-16 11:14:08 [INFO]\t[TRAIN] epoch: 1, iter: 840/80000, loss: 0.5477, lr: 0.009906, batch_cost: 0.5038, reader_cost: 0.00011, ips: 7.9401 samples/sec | ETA 11:04:38\n",
      "2021-10-16 11:14:13 [INFO]\t[TRAIN] epoch: 1, iter: 850/80000, loss: 0.6556, lr: 0.009904, batch_cost: 0.5028, reader_cost: 0.00011, ips: 7.9558 samples/sec | ETA 11:03:14\n",
      "2021-10-16 11:14:18 [INFO]\t[TRAIN] epoch: 1, iter: 860/80000, loss: 0.6384, lr: 0.009903, batch_cost: 0.5029, reader_cost: 0.00011, ips: 7.9532 samples/sec | ETA 11:03:22\n",
      "2021-10-16 11:14:23 [INFO]\t[TRAIN] epoch: 1, iter: 870/80000, loss: 0.6593, lr: 0.009902, batch_cost: 0.5023, reader_cost: 0.00011, ips: 7.9634 samples/sec | ETA 11:02:26\n",
      "2021-10-16 11:14:28 [INFO]\t[TRAIN] epoch: 1, iter: 880/80000, loss: 0.6637, lr: 0.009901, batch_cost: 0.5031, reader_cost: 0.00010, ips: 7.9512 samples/sec | ETA 11:03:22\n",
      "2021-10-16 11:14:33 [INFO]\t[TRAIN] epoch: 1, iter: 890/80000, loss: 0.6239, lr: 0.009900, batch_cost: 0.5028, reader_cost: 0.00009, ips: 7.9548 samples/sec | ETA 11:02:59\n",
      "2021-10-16 11:14:38 [INFO]\t[TRAIN] epoch: 1, iter: 900/80000, loss: 0.7396, lr: 0.009899, batch_cost: 0.5037, reader_cost: 0.00010, ips: 7.9412 samples/sec | ETA 11:04:02\n",
      "2021-10-16 11:14:43 [INFO]\t[TRAIN] epoch: 1, iter: 910/80000, loss: 0.7018, lr: 0.009898, batch_cost: 0.5021, reader_cost: 0.00010, ips: 7.9670 samples/sec | ETA 11:01:49\n",
      "2021-10-16 11:14:48 [INFO]\t[TRAIN] epoch: 1, iter: 920/80000, loss: 0.5717, lr: 0.009897, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9523 samples/sec | ETA 11:02:57\n",
      "2021-10-16 11:14:53 [INFO]\t[TRAIN] epoch: 1, iter: 930/80000, loss: 0.6049, lr: 0.009895, batch_cost: 0.5026, reader_cost: 0.00012, ips: 7.9586 samples/sec | ETA 11:02:20\n",
      "2021-10-16 11:14:58 [INFO]\t[TRAIN] epoch: 1, iter: 940/80000, loss: 0.5809, lr: 0.009894, batch_cost: 0.5033, reader_cost: 0.00011, ips: 7.9471 samples/sec | ETA 11:03:13\n",
      "2021-10-16 11:15:03 [INFO]\t[TRAIN] epoch: 1, iter: 950/80000, loss: 0.6811, lr: 0.009893, batch_cost: 0.5018, reader_cost: 0.00009, ips: 7.9715 samples/sec | ETA 11:01:06\n",
      "2021-10-16 11:15:08 [INFO]\t[TRAIN] epoch: 1, iter: 960/80000, loss: 0.6242, lr: 0.009892, batch_cost: 0.5031, reader_cost: 0.00011, ips: 7.9511 samples/sec | ETA 11:02:43\n",
      "2021-10-16 11:15:13 [INFO]\t[TRAIN] epoch: 1, iter: 970/80000, loss: 0.6420, lr: 0.009891, batch_cost: 0.5026, reader_cost: 0.00010, ips: 7.9587 samples/sec | ETA 11:02:00\n",
      "2021-10-16 11:15:18 [INFO]\t[TRAIN] epoch: 1, iter: 980/80000, loss: 0.5881, lr: 0.009890, batch_cost: 0.5035, reader_cost: 0.00011, ips: 7.9447 samples/sec | ETA 11:03:04\n",
      "2021-10-16 11:15:23 [INFO]\t[TRAIN] epoch: 1, iter: 990/80000, loss: 0.6027, lr: 0.009889, batch_cost: 0.5032, reader_cost: 0.00011, ips: 7.9492 samples/sec | ETA 11:02:37\n",
      "2021-10-16 11:15:28 [INFO]\t[TRAIN] epoch: 1, iter: 1000/80000, loss: 0.5953, lr: 0.009888, batch_cost: 0.5034, reader_cost: 0.00011, ips: 7.9463 samples/sec | ETA 11:02:46\n",
      "2021-10-16 11:15:28 [INFO]\tStart evaluating (total_samples: 19996, total_iters: 19996)...\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:239: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int32, but right dtype is paddle.bool, the right dtype will convert to paddle.int32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:239: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.bool, the right dtype will convert to paddle.int64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "19996/19996 [==============================] - 698s 35ms/step - batch_cost: 0.0348 - reader cost: 0.00\n",
      "2021-10-16 11:27:06 [INFO]\t[EVAL] #Images: 19996 mIoU: 0.3706 Acc: 0.5511 Kappa: 0.3937 \n",
      "2021-10-16 11:27:06 [INFO]\t[EVAL] Class IoU: \n",
      "[0.2909 0.6161 0.3305 0.245 ]\n",
      "2021-10-16 11:27:06 [INFO]\t[EVAL] Class Acc: \n",
      "[0.4863 0.8331 0.4602 0.3417]\n",
      "2021-10-16 11:27:06 [INFO]\t[EVAL] The model with the best validation mIoU (0.3706) was saved at iter 1000.\n",
      "2021-10-16 11:27:11 [INFO]\t[TRAIN] epoch: 1, iter: 1010/80000, loss: 0.6332, lr: 0.009886, batch_cost: 0.5030, reader_cost: 0.00010, ips: 7.9522 samples/sec | ETA 11:02:12\n",
      "2021-10-16 11:27:17 [INFO]\t[TRAIN] epoch: 1, iter: 1020/80000, loss: 0.7022, lr: 0.009885, batch_cost: 0.5285, reader_cost: 0.00012, ips: 7.5689 samples/sec | ETA 11:35:39\n",
      "2021-10-16 11:27:22 [INFO]\t[TRAIN] epoch: 1, iter: 1030/80000, loss: 0.6372, lr: 0.009884, batch_cost: 0.5092, reader_cost: 0.00012, ips: 7.8553 samples/sec | ETA 11:10:12\n",
      "2021-10-16 11:27:27 [INFO]\t[TRAIN] epoch: 1, iter: 1040/80000, loss: 0.6352, lr: 0.009883, batch_cost: 0.5097, reader_cost: 0.00013, ips: 7.8473 samples/sec | ETA 11:10:48\n",
      "2021-10-16 11:27:32 [INFO]\t[TRAIN] epoch: 1, iter: 1050/80000, loss: 0.6316, lr: 0.009882, batch_cost: 0.5095, reader_cost: 0.00013, ips: 7.8502 samples/sec | ETA 11:10:28\n",
      "2021-10-16 11:27:37 [INFO]\t[TRAIN] epoch: 1, iter: 1060/80000, loss: 0.6352, lr: 0.009881, batch_cost: 0.5076, reader_cost: 0.00013, ips: 7.8800 samples/sec | ETA 11:07:50\n",
      "2021-10-16 11:27:42 [INFO]\t[TRAIN] epoch: 1, iter: 1070/80000, loss: 0.5914, lr: 0.009880, batch_cost: 0.5075, reader_cost: 0.00012, ips: 7.8816 samples/sec | ETA 11:07:37\n",
      "2021-10-16 11:27:47 [INFO]\t[TRAIN] epoch: 1, iter: 1080/80000, loss: 0.5292, lr: 0.009879, batch_cost: 0.5091, reader_cost: 0.00010, ips: 7.8570 samples/sec | ETA 11:09:38\n",
      "2021-10-16 11:27:52 [INFO]\t[TRAIN] epoch: 1, iter: 1090/80000, loss: 0.6035, lr: 0.009877, batch_cost: 0.5084, reader_cost: 0.00010, ips: 7.8674 samples/sec | ETA 11:08:39\n",
      "2021-10-16 11:27:57 [INFO]\t[TRAIN] epoch: 1, iter: 1100/80000, loss: 0.6531, lr: 0.009876, batch_cost: 0.5066, reader_cost: 0.00083, ips: 7.8951 samples/sec | ETA 11:06:13\n",
      "2021-10-16 11:28:02 [INFO]\t[TRAIN] epoch: 1, iter: 1110/80000, loss: 0.5935, lr: 0.009875, batch_cost: 0.5037, reader_cost: 0.00011, ips: 7.9413 samples/sec | ETA 11:02:16\n",
      "2021-10-16 11:28:07 [INFO]\t[TRAIN] epoch: 1, iter: 1120/80000, loss: 0.6064, lr: 0.009874, batch_cost: 0.5040, reader_cost: 0.00012, ips: 7.9370 samples/sec | ETA 11:02:32\n",
      "2021-10-16 11:28:13 [INFO]\t[TRAIN] epoch: 1, iter: 1130/80000, loss: 0.6927, lr: 0.009873, batch_cost: 0.5156, reader_cost: 0.00011, ips: 7.7572 samples/sec | ETA 11:17:49\n",
      "2021-10-16 11:28:18 [INFO]\t[TRAIN] epoch: 1, iter: 1140/80000, loss: 0.5988, lr: 0.009872, batch_cost: 0.5038, reader_cost: 0.00011, ips: 7.9403 samples/sec | ETA 11:02:06\n",
      "2021-10-16 11:28:23 [INFO]\t[TRAIN] epoch: 1, iter: 1150/80000, loss: 0.5651, lr: 0.009871, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9525 samples/sec | ETA 11:01:00\n",
      "2021-10-16 11:28:28 [INFO]\t[TRAIN] epoch: 1, iter: 1160/80000, loss: 0.5239, lr: 0.009870, batch_cost: 0.5025, reader_cost: 0.00011, ips: 7.9610 samples/sec | ETA 11:00:13\n",
      "2021-10-16 11:28:33 [INFO]\t[TRAIN] epoch: 1, iter: 1170/80000, loss: 0.6684, lr: 0.009868, batch_cost: 0.5028, reader_cost: 0.00011, ips: 7.9547 samples/sec | ETA 11:00:39\n",
      "2021-10-16 11:28:38 [INFO]\t[TRAIN] epoch: 1, iter: 1180/80000, loss: 0.5787, lr: 0.009867, batch_cost: 0.5019, reader_cost: 0.00011, ips: 7.9697 samples/sec | ETA 10:59:20\n",
      "2021-10-16 11:28:43 [INFO]\t[TRAIN] epoch: 1, iter: 1190/80000, loss: 0.6363, lr: 0.009866, batch_cost: 0.5037, reader_cost: 0.00010, ips: 7.9405 samples/sec | ETA 11:01:40\n",
      "2021-10-16 11:28:48 [INFO]\t[TRAIN] epoch: 1, iter: 1200/80000, loss: 0.6887, lr: 0.009865, batch_cost: 0.5033, reader_cost: 0.00011, ips: 7.9476 samples/sec | ETA 11:00:59\n",
      "2021-10-16 11:28:53 [INFO]\t[TRAIN] epoch: 1, iter: 1210/80000, loss: 0.5635, lr: 0.009864, batch_cost: 0.5026, reader_cost: 0.00012, ips: 7.9584 samples/sec | ETA 11:00:01\n",
      "2021-10-16 11:28:58 [INFO]\t[TRAIN] epoch: 1, iter: 1220/80000, loss: 0.5965, lr: 0.009863, batch_cost: 0.5032, reader_cost: 0.00012, ips: 7.9489 samples/sec | ETA 11:00:43\n",
      "2021-10-16 11:29:03 [INFO]\t[TRAIN] epoch: 1, iter: 1230/80000, loss: 0.5228, lr: 0.009862, batch_cost: 0.5106, reader_cost: 0.00010, ips: 7.8344 samples/sec | ETA 11:10:17\n",
      "2021-10-16 11:29:08 [INFO]\t[TRAIN] epoch: 1, iter: 1240/80000, loss: 0.6394, lr: 0.009861, batch_cost: 0.5256, reader_cost: 0.00012, ips: 7.6103 samples/sec | ETA 11:29:56\n",
      "2021-10-16 11:29:13 [INFO]\t[TRAIN] epoch: 1, iter: 1250/80000, loss: 0.6964, lr: 0.009859, batch_cost: 0.5075, reader_cost: 0.00014, ips: 7.8811 samples/sec | ETA 11:06:09\n",
      "2021-10-16 11:29:18 [INFO]\t[TRAIN] epoch: 1, iter: 1260/80000, loss: 0.5169, lr: 0.009858, batch_cost: 0.5098, reader_cost: 0.00013, ips: 7.8469 samples/sec | ETA 11:08:58\n",
      "2021-10-16 11:29:24 [INFO]\t[TRAIN] epoch: 1, iter: 1270/80000, loss: 0.5878, lr: 0.009857, batch_cost: 0.5095, reader_cost: 0.00011, ips: 7.8514 samples/sec | ETA 11:08:29\n",
      "2021-10-16 11:29:29 [INFO]\t[TRAIN] epoch: 1, iter: 1280/80000, loss: 0.6283, lr: 0.009856, batch_cost: 0.5039, reader_cost: 0.00012, ips: 7.9386 samples/sec | ETA 11:01:04\n",
      "2021-10-16 11:29:34 [INFO]\t[TRAIN] epoch: 1, iter: 1290/80000, loss: 0.5373, lr: 0.009855, batch_cost: 0.5039, reader_cost: 0.00013, ips: 7.9373 samples/sec | ETA 11:01:05\n",
      "2021-10-16 11:29:39 [INFO]\t[TRAIN] epoch: 1, iter: 1300/80000, loss: 0.5996, lr: 0.009854, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9526 samples/sec | ETA 10:59:44\n",
      "2021-10-16 11:29:44 [INFO]\t[TRAIN] epoch: 1, iter: 1310/80000, loss: 0.6217, lr: 0.009853, batch_cost: 0.5027, reader_cost: 0.00010, ips: 7.9578 samples/sec | ETA 10:59:13\n",
      "2021-10-16 11:29:49 [INFO]\t[TRAIN] epoch: 1, iter: 1320/80000, loss: 0.5584, lr: 0.009851, batch_cost: 0.5034, reader_cost: 0.00011, ips: 7.9456 samples/sec | ETA 11:00:09\n",
      "2021-10-16 11:29:54 [INFO]\t[TRAIN] epoch: 1, iter: 1330/80000, loss: 0.5663, lr: 0.009850, batch_cost: 0.5021, reader_cost: 0.00010, ips: 7.9665 samples/sec | ETA 10:58:20\n",
      "2021-10-16 11:29:59 [INFO]\t[TRAIN] epoch: 1, iter: 1340/80000, loss: 0.6831, lr: 0.009849, batch_cost: 0.5258, reader_cost: 0.00011, ips: 7.6079 samples/sec | ETA 11:29:17\n",
      "2021-10-16 11:30:04 [INFO]\t[TRAIN] epoch: 1, iter: 1350/80000, loss: 0.5981, lr: 0.009848, batch_cost: 0.5019, reader_cost: 0.00010, ips: 7.9695 samples/sec | ETA 10:57:55\n",
      "2021-10-16 11:30:09 [INFO]\t[TRAIN] epoch: 1, iter: 1360/80000, loss: 0.5869, lr: 0.009847, batch_cost: 0.5037, reader_cost: 0.00012, ips: 7.9419 samples/sec | ETA 11:00:07\n",
      "2021-10-16 11:30:14 [INFO]\t[TRAIN] epoch: 1, iter: 1370/80000, loss: 0.6516, lr: 0.009846, batch_cost: 0.5034, reader_cost: 0.00010, ips: 7.9456 samples/sec | ETA 10:59:44\n",
      "2021-10-16 11:30:19 [INFO]\t[TRAIN] epoch: 1, iter: 1380/80000, loss: 0.5393, lr: 0.009845, batch_cost: 0.5029, reader_cost: 0.00012, ips: 7.9534 samples/sec | ETA 10:59:00\n",
      "2021-10-16 11:30:24 [INFO]\t[TRAIN] epoch: 1, iter: 1390/80000, loss: 0.6595, lr: 0.009844, batch_cost: 0.5033, reader_cost: 0.00011, ips: 7.9479 samples/sec | ETA 10:59:22\n",
      "2021-10-16 11:30:29 [INFO]\t[TRAIN] epoch: 1, iter: 1400/80000, loss: 0.5493, lr: 0.009842, batch_cost: 0.5029, reader_cost: 0.00011, ips: 7.9544 samples/sec | ETA 10:58:45\n",
      "2021-10-16 11:30:34 [INFO]\t[TRAIN] epoch: 1, iter: 1410/80000, loss: 0.6661, lr: 0.009841, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9525 samples/sec | ETA 10:58:49\n",
      "2021-10-16 11:30:39 [INFO]\t[TRAIN] epoch: 1, iter: 1420/80000, loss: 0.6768, lr: 0.009840, batch_cost: 0.5046, reader_cost: 0.00011, ips: 7.9278 samples/sec | ETA 11:00:47\n",
      "2021-10-16 11:30:44 [INFO]\t[TRAIN] epoch: 1, iter: 1430/80000, loss: 0.5721, lr: 0.009839, batch_cost: 0.5034, reader_cost: 0.00011, ips: 7.9461 samples/sec | ETA 10:59:11\n",
      "2021-10-16 11:30:49 [INFO]\t[TRAIN] epoch: 1, iter: 1440/80000, loss: 0.5710, lr: 0.009838, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9520 samples/sec | ETA 10:58:37\n",
      "2021-10-16 11:30:54 [INFO]\t[TRAIN] epoch: 1, iter: 1450/80000, loss: 0.5246, lr: 0.009837, batch_cost: 0.5211, reader_cost: 0.00014, ips: 7.6762 samples/sec | ETA 11:22:11\n",
      "2021-10-16 11:31:00 [INFO]\t[TRAIN] epoch: 1, iter: 1460/80000, loss: 0.6354, lr: 0.009836, batch_cost: 0.5093, reader_cost: 0.00013, ips: 7.8535 samples/sec | ETA 11:06:42\n",
      "2021-10-16 11:31:05 [INFO]\t[TRAIN] epoch: 1, iter: 1470/80000, loss: 0.6125, lr: 0.009835, batch_cost: 0.5030, reader_cost: 0.00012, ips: 7.9527 samples/sec | ETA 10:58:18\n",
      "2021-10-16 11:31:10 [INFO]\t[TRAIN] epoch: 1, iter: 1480/80000, loss: 0.6564, lr: 0.009833, batch_cost: 0.5025, reader_cost: 0.00012, ips: 7.9595 samples/sec | ETA 10:57:39\n",
      "2021-10-16 11:31:15 [INFO]\t[TRAIN] epoch: 1, iter: 1490/80000, loss: 0.5886, lr: 0.009832, batch_cost: 0.5025, reader_cost: 0.00011, ips: 7.9604 samples/sec | ETA 10:57:30\n",
      "2021-10-16 11:31:20 [INFO]\t[TRAIN] epoch: 1, iter: 1500/80000, loss: 0.5555, lr: 0.009831, batch_cost: 0.5020, reader_cost: 0.00012, ips: 7.9684 samples/sec | ETA 10:56:45\n",
      "2021-10-16 11:31:25 [INFO]\t[TRAIN] epoch: 1, iter: 1510/80000, loss: 0.6365, lr: 0.009830, batch_cost: 0.5028, reader_cost: 0.00011, ips: 7.9560 samples/sec | ETA 10:57:42\n",
      "2021-10-16 11:31:30 [INFO]\t[TRAIN] epoch: 1, iter: 1520/80000, loss: 0.5806, lr: 0.009829, batch_cost: 0.5037, reader_cost: 0.00012, ips: 7.9418 samples/sec | ETA 10:58:47\n",
      "2021-10-16 11:31:35 [INFO]\t[TRAIN] epoch: 1, iter: 1530/80000, loss: 0.5932, lr: 0.009828, batch_cost: 0.5033, reader_cost: 0.00012, ips: 7.9482 samples/sec | ETA 10:58:10\n",
      "2021-10-16 11:31:40 [INFO]\t[TRAIN] epoch: 1, iter: 1540/80000, loss: 0.6305, lr: 0.009827, batch_cost: 0.5034, reader_cost: 0.00013, ips: 7.9453 samples/sec | ETA 10:58:19\n",
      "2021-10-16 11:31:45 [INFO]\t[TRAIN] epoch: 1, iter: 1550/80000, loss: 0.6474, lr: 0.009826, batch_cost: 0.5073, reader_cost: 0.00012, ips: 7.8841 samples/sec | ETA 11:03:21\n",
      "2021-10-16 11:31:50 [INFO]\t[TRAIN] epoch: 1, iter: 1560/80000, loss: 0.4831, lr: 0.009824, batch_cost: 0.5032, reader_cost: 0.00012, ips: 7.9496 samples/sec | ETA 10:57:48\n",
      "2021-10-16 11:31:55 [INFO]\t[TRAIN] epoch: 1, iter: 1570/80000, loss: 0.5286, lr: 0.009823, batch_cost: 0.5060, reader_cost: 0.00121, ips: 7.9048 samples/sec | ETA 11:01:27\n",
      "2021-10-16 11:32:00 [INFO]\t[TRAIN] epoch: 1, iter: 1580/80000, loss: 0.5604, lr: 0.009822, batch_cost: 0.5030, reader_cost: 0.00012, ips: 7.9526 samples/sec | ETA 10:57:23\n",
      "2021-10-16 11:32:05 [INFO]\t[TRAIN] epoch: 1, iter: 1590/80000, loss: 0.5916, lr: 0.009821, batch_cost: 0.5034, reader_cost: 0.00011, ips: 7.9461 samples/sec | ETA 10:57:51\n",
      "2021-10-16 11:32:10 [INFO]\t[TRAIN] epoch: 1, iter: 1600/80000, loss: 0.6327, lr: 0.009820, batch_cost: 0.5035, reader_cost: 0.00011, ips: 7.9439 samples/sec | ETA 10:57:57\n",
      "2021-10-16 11:32:15 [INFO]\t[TRAIN] epoch: 1, iter: 1610/80000, loss: 0.6100, lr: 0.009819, batch_cost: 0.5023, reader_cost: 0.00011, ips: 7.9639 samples/sec | ETA 10:56:12\n",
      "2021-10-16 11:32:20 [INFO]\t[TRAIN] epoch: 1, iter: 1620/80000, loss: 0.6132, lr: 0.009818, batch_cost: 0.5019, reader_cost: 0.00012, ips: 7.9700 samples/sec | ETA 10:55:37\n",
      "2021-10-16 11:32:25 [INFO]\t[TRAIN] epoch: 1, iter: 1630/80000, loss: 0.6263, lr: 0.009817, batch_cost: 0.5028, reader_cost: 0.00011, ips: 7.9552 samples/sec | ETA 10:56:45\n",
      "2021-10-16 11:32:30 [INFO]\t[TRAIN] epoch: 1, iter: 1640/80000, loss: 0.5940, lr: 0.009815, batch_cost: 0.5041, reader_cost: 0.00010, ips: 7.9351 samples/sec | ETA 10:58:20\n",
      "2021-10-16 11:32:35 [INFO]\t[TRAIN] epoch: 1, iter: 1650/80000, loss: 0.5996, lr: 0.009814, batch_cost: 0.5024, reader_cost: 0.00010, ips: 7.9625 samples/sec | ETA 10:55:59\n",
      "2021-10-16 11:32:40 [INFO]\t[TRAIN] epoch: 1, iter: 1660/80000, loss: 0.6269, lr: 0.009813, batch_cost: 0.5177, reader_cost: 0.00020, ips: 7.7269 samples/sec | ETA 11:15:54\n",
      "2021-10-16 11:32:45 [INFO]\t[TRAIN] epoch: 1, iter: 1670/80000, loss: 0.5608, lr: 0.009812, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9525 samples/sec | ETA 10:56:38\n",
      "2021-10-16 11:32:50 [INFO]\t[TRAIN] epoch: 1, iter: 1680/80000, loss: 0.6884, lr: 0.009811, batch_cost: 0.5045, reader_cost: 0.00011, ips: 7.9281 samples/sec | ETA 10:58:35\n",
      "2021-10-16 11:32:56 [INFO]\t[TRAIN] epoch: 1, iter: 1690/80000, loss: 0.6125, lr: 0.009810, batch_cost: 0.5032, reader_cost: 0.00009, ips: 7.9491 samples/sec | ETA 10:56:45\n",
      "2021-10-16 11:33:01 [INFO]\t[TRAIN] epoch: 1, iter: 1700/80000, loss: 0.5889, lr: 0.009809, batch_cost: 0.5033, reader_cost: 0.00011, ips: 7.9476 samples/sec | ETA 10:56:48\n",
      "2021-10-16 11:33:06 [INFO]\t[TRAIN] epoch: 1, iter: 1710/80000, loss: 0.6548, lr: 0.009808, batch_cost: 0.5024, reader_cost: 0.00010, ips: 7.9614 samples/sec | ETA 10:55:34\n",
      "2021-10-16 11:33:11 [INFO]\t[TRAIN] epoch: 1, iter: 1720/80000, loss: 0.5936, lr: 0.009806, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9522 samples/sec | ETA 10:56:15\n",
      "2021-10-16 11:33:16 [INFO]\t[TRAIN] epoch: 1, iter: 1730/80000, loss: 0.5930, lr: 0.009805, batch_cost: 0.5032, reader_cost: 0.00011, ips: 7.9488 samples/sec | ETA 10:56:27\n",
      "2021-10-16 11:33:21 [INFO]\t[TRAIN] epoch: 1, iter: 1740/80000, loss: 0.5830, lr: 0.009804, batch_cost: 0.5038, reader_cost: 0.00012, ips: 7.9396 samples/sec | ETA 10:57:07\n",
      "2021-10-16 11:33:26 [INFO]\t[TRAIN] epoch: 1, iter: 1750/80000, loss: 0.5997, lr: 0.009803, batch_cost: 0.4998, reader_cost: 0.00011, ips: 8.0030 samples/sec | ETA 10:51:50\n",
      "2021-10-16 11:33:31 [INFO]\t[TRAIN] epoch: 1, iter: 1760/80000, loss: 0.6828, lr: 0.009802, batch_cost: 0.5155, reader_cost: 0.00012, ips: 7.7597 samples/sec | ETA 11:12:11\n",
      "2021-10-16 11:33:36 [INFO]\t[TRAIN] epoch: 1, iter: 1770/80000, loss: 0.6513, lr: 0.009801, batch_cost: 0.5024, reader_cost: 0.00011, ips: 7.9611 samples/sec | ETA 10:55:06\n",
      "2021-10-16 11:33:41 [INFO]\t[TRAIN] epoch: 1, iter: 1780/80000, loss: 0.5584, lr: 0.009800, batch_cost: 0.5032, reader_cost: 0.00011, ips: 7.9484 samples/sec | ETA 10:56:03\n",
      "2021-10-16 11:33:46 [INFO]\t[TRAIN] epoch: 1, iter: 1790/80000, loss: 0.5975, lr: 0.009799, batch_cost: 0.5025, reader_cost: 0.00010, ips: 7.9600 samples/sec | ETA 10:55:01\n",
      "2021-10-16 11:33:51 [INFO]\t[TRAIN] epoch: 1, iter: 1800/80000, loss: 0.6366, lr: 0.009797, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9528 samples/sec | ETA 10:55:31\n",
      "2021-10-16 11:33:56 [INFO]\t[TRAIN] epoch: 1, iter: 1810/80000, loss: 0.6238, lr: 0.009796, batch_cost: 0.5028, reader_cost: 0.00010, ips: 7.9548 samples/sec | ETA 10:55:17\n",
      "2021-10-16 11:34:01 [INFO]\t[TRAIN] epoch: 1, iter: 1820/80000, loss: 0.5824, lr: 0.009795, batch_cost: 0.5036, reader_cost: 0.00010, ips: 7.9427 samples/sec | ETA 10:56:11\n",
      "2021-10-16 11:34:06 [INFO]\t[TRAIN] epoch: 1, iter: 1830/80000, loss: 0.5793, lr: 0.009794, batch_cost: 0.5032, reader_cost: 0.00011, ips: 7.9497 samples/sec | ETA 10:55:32\n",
      "2021-10-16 11:34:11 [INFO]\t[TRAIN] epoch: 1, iter: 1840/80000, loss: 0.6308, lr: 0.009793, batch_cost: 0.5027, reader_cost: 0.00011, ips: 7.9576 samples/sec | ETA 10:54:48\n",
      "2021-10-16 11:34:16 [INFO]\t[TRAIN] epoch: 1, iter: 1850/80000, loss: 0.6045, lr: 0.009792, batch_cost: 0.5036, reader_cost: 0.00011, ips: 7.9426 samples/sec | ETA 10:55:57\n",
      "2021-10-16 11:34:21 [INFO]\t[TRAIN] epoch: 1, iter: 1860/80000, loss: 0.6014, lr: 0.009791, batch_cost: 0.5031, reader_cost: 0.00012, ips: 7.9506 samples/sec | ETA 10:55:12\n",
      "2021-10-16 11:34:26 [INFO]\t[TRAIN] epoch: 1, iter: 1870/80000, loss: 0.6292, lr: 0.009789, batch_cost: 0.5063, reader_cost: 0.00012, ips: 7.9012 samples/sec | ETA 10:59:13\n",
      "2021-10-16 11:34:31 [INFO]\t[TRAIN] epoch: 1, iter: 1880/80000, loss: 0.7119, lr: 0.009788, batch_cost: 0.5030, reader_cost: 0.00013, ips: 7.9519 samples/sec | ETA 10:54:56\n",
      "2021-10-16 11:34:36 [INFO]\t[TRAIN] epoch: 1, iter: 1890/80000, loss: 0.5768, lr: 0.009787, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9527 samples/sec | ETA 10:54:47\n",
      "2021-10-16 11:34:41 [INFO]\t[TRAIN] epoch: 1, iter: 1900/80000, loss: 0.6452, lr: 0.009786, batch_cost: 0.5037, reader_cost: 0.00011, ips: 7.9406 samples/sec | ETA 10:55:41\n",
      "2021-10-16 11:34:46 [INFO]\t[TRAIN] epoch: 1, iter: 1910/80000, loss: 0.6675, lr: 0.009785, batch_cost: 0.5030, reader_cost: 0.00011, ips: 7.9520 samples/sec | ETA 10:54:40\n",
      "2021-10-16 11:34:51 [INFO]\t[TRAIN] epoch: 1, iter: 1920/80000, loss: 0.5927, lr: 0.009784, batch_cost: 0.5020, reader_cost: 0.00011, ips: 7.9686 samples/sec | ETA 10:53:13\n",
      "2021-10-16 11:34:56 [INFO]\t[TRAIN] epoch: 1, iter: 1930/80000, loss: 0.6825, lr: 0.009783, batch_cost: 0.5027, reader_cost: 0.00011, ips: 7.9567 samples/sec | ETA 10:54:07\n",
      "2021-10-16 11:35:01 [INFO]\t[TRAIN] epoch: 1, iter: 1940/80000, loss: 0.5996, lr: 0.009782, batch_cost: 0.5034, reader_cost: 0.00011, ips: 7.9454 samples/sec | ETA 10:54:58\n",
      "2021-10-16 11:35:07 [INFO]\t[TRAIN] epoch: 1, iter: 1950/80000, loss: 0.6875, lr: 0.009780, batch_cost: 0.5091, reader_cost: 0.00011, ips: 7.8575 samples/sec | ETA 11:02:12\n",
      "2021-10-16 11:35:12 [INFO]\t[TRAIN] epoch: 1, iter: 1960/80000, loss: 0.5695, lr: 0.009779, batch_cost: 0.5087, reader_cost: 0.00011, ips: 7.8629 samples/sec | ETA 11:01:40\n",
      "2021-10-16 11:35:17 [INFO]\t[TRAIN] epoch: 1, iter: 1970/80000, loss: 0.6107, lr: 0.009778, batch_cost: 0.5098, reader_cost: 0.00011, ips: 7.8458 samples/sec | ETA 11:03:01\n",
      "2021-10-16 11:35:22 [INFO]\t[TRAIN] epoch: 1, iter: 1980/80000, loss: 0.6565, lr: 0.009777, batch_cost: 0.5275, reader_cost: 0.00019, ips: 7.5834 samples/sec | ETA 11:25:53\n",
      "2021-10-16 11:35:27 [INFO]\t[TRAIN] epoch: 1, iter: 1990/80000, loss: 0.6953, lr: 0.009776, batch_cost: 0.5031, reader_cost: 0.00011, ips: 7.9513 samples/sec | ETA 10:54:03\n",
      "2021-10-16 11:35:32 [INFO]\t[TRAIN] epoch: 1, iter: 2000/80000, loss: 0.5512, lr: 0.009775, batch_cost: 0.5031, reader_cost: 0.00011, ips: 7.9508 samples/sec | ETA 10:54:01\n",
      "2021-10-16 11:35:32 [INFO]\tStart evaluating (total_samples: 19996, total_iters: 19996)...\n",
      "  834/19996 [>.............................] - ETA: 10:54 - batch_cost: 0.0341 - reader cost: 6.1740e-05\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 190, in <module>\n",
      "    main(args)\n",
      "  File \"train.py\", line 185, in main\n",
      "    fp16=args.fp16)\n",
      "  File \"/home/aistudio/work/PaddleSeg/paddleseg/core/train.py\", line 260, in train\n",
      "    model, val_dataset, num_workers=num_workers, **test_config)\n",
      "  File \"/home/aistudio/work/PaddleSeg/paddleseg/core/val.py\", line 119, in evaluate\n",
      "    crop_size=crop_size)\n",
      "  File \"/home/aistudio/work/PaddleSeg/paddleseg/core/infer.py\", line 218, in inference\n",
      "    logits = model(im)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/work/PaddleSeg/paddleseg/models/deeplab.py\", line 83, in forward\n",
      "    logit_list = self.head(feat_list)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/work/PaddleSeg/paddleseg/models/deeplab.py\", line 153, in forward\n",
      "    logit = self.decoder(x, low_level_feat)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 902, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/work/PaddleSeg/paddleseg/models/deeplab.py\", line 293, in forward\n",
      "    low_level_shape = paddle.shape(low_level_feat)[-2:]\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\", line 11275, in shape\n",
      "    ['bool', 'float16', 'float32', 'float64', 'int32', 'int64'], 'shape')\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 82, in check_variable_and_dtype\n",
      "    check_dtype(input.dtype, input_name, expected_dtype, op_name, extra_message)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 运行代码\r\n",
    "%cd /home/aistudio/work/PaddleSeg\r\n",
    "!python train.py --config configs/deeplabv3p/deeplabv3p_remote.yml --do_eval --use_vdl --save_interval 1000 --save_dir output/models_remote/deeplabv3p\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 生成测试集结果\n",
    "\n",
    "模型的训练过程比较漫长，算力卡不足的同学，可以使用中断，在配置文件中设置pretrained字段，从中断开始训练即可。\n",
    "\n",
    "训练好的模型将会被保存在`work/PaddleSeg/output/models_remote/deeplabv3p/best_model`目录下，生成测试结果时，需要和官方要求的颜色保持一致，我们要将`PaddleSeg/paddleseg/utils/visualize.py`中第90行修改为\n",
    "`color_map = [0,0,0, 1,1,1, 2,2,2, 3,3,3]`，之后执行下面验证的流程即可。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/PaddleSeg\n",
      "2021-10-16 11:56:05 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 4\n",
      "iters: 80000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: DiceLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.01\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  align_corners: true\n",
      "  aspp_out_channels: 256\n",
      "  aspp_ratios:\n",
      "  - 1\n",
      "  - 12\n",
      "  - 24\n",
      "  - 36\n",
      "  backbone:\n",
      "    multi_grid:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    output_stride: 8\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "    type: ResNet50_vd\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 3\n",
      "  type: DeepLabV3P\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio/data/data80164/\n",
      "  mode: train\n",
      "  num_classes: 4\n",
      "  train_path: /home/aistudio/data/data80164/train.txt\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio/data/data80164/\n",
      "  mode: val\n",
      "  num_classes: 4\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/data/data80164/val.txt\n",
      "------------------------------------------------\n",
      "W1016 11:56:06.108417 10460 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1016 11:56:06.108458 10460 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "2021-10-16 11:56:14 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "2021-10-16 11:56:16 [INFO]\tThere are 275/275 variables loaded into ResNet_vd.\n",
      "2021-10-16 11:56:16 [INFO]\tNumber of predict images = 4608\n",
      "2021-10-16 11:56:16 [INFO]\tLoading pretrained model from output/models_remote/deeplabv3p/best_model/model.pdparams\n",
      "2021-10-16 11:56:18 [INFO]\tThere are 360/360 variables loaded into DeepLabV3P.\n",
      "2021-10-16 11:56:18 [INFO]\tStart to predict...\n",
      "4608/4608 [==============================] - 178s 39ms/ste\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/work/PaddleSeg\r\n",
    "!python predict.py --config configs/deeplabv3p/deeplabv3p_remote.yml --model_path output/models_remote/deeplabv3p/best_model/model.pdparams --image_path /home/aistudio/data/data80164/img_testA --save_dir output/result_remote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 提交结果\n",
    "结果将会保存在`work/PaddleSeg/output/result_remote/added_prediction` 目录下，下载之后提交即可\n",
    "\n",
    "本次常规赛主要是借助了paddleseg框架完成了这次语义分割任务，通过deeplabv3p+diceloss的形式就可以拿到不错的成绩，后面还需要继续学习相关知识，可以利用后面的机会在ocrnet等更高级的语义分割网络上做做实验，还有在优化器和损失函数上也有很多需要改进的地方。\n",
    "\n",
    "最后，感觉paddle提供了这么方便的平台，提供的V100非常给力，paddle赞！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
